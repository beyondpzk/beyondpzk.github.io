<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> SurveyOnWorldModelsForEmbodiedAI | Tenacious life, proud journey. </title> <meta name="author" content="P W Name"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://beyondpzk.github.io/blog/2025/SurveyOnWorldModelsForEmbodiedAI/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Tenacious life, proud journey. </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">SurveyOnWorldModelsForEmbodiedAI</h1> <p class="post-meta"> Created on October 19, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>[TOC]</p> <h1 id="surveyonworldmodelsforembodiedai">SurveyOnWorldModelsForEmbodiedAI</h1> <p><a href="https://arxiv.org/abs/2510.16732" rel="external nofollow noopener" target="_blank">论文链接</a></p> <h1 id="具身智能中的世界模型-world-models-for-embodied-ai">具身智能中的世界模型 (World Models for Embodied AI)</h1> <hr> <h2 id="引言与概念基础">引言与概念基础</h2> <p><strong>目标</strong>：理解什么是世界模型，它与传统视觉模型的区别，以及其在具身智能中的历史演变。</p> <h3 id="1-人类认知的启示">1. 人类认知的启示</h3> <p>我们先思考一个认知科学的问题：人类是如何在复杂的环境中行动的？当我们走在一个拥挤的街道上，我们不仅是在“看”，我们还在“预测”。如果我们快步走，我们知道前面的行人可能会避让；如果我们撞到障碍物，我们知道会发生什么。</p> <p>认知科学表明，人类通过整合感官输入构建世界的内部模型。这些模型不仅预测和模拟未来事件，还塑造感知并指导行动 <alphaxiv-paper-citation title="Cognitive Science" page="1" first="Cognitive science suggests" last="guide action"></alphaxiv-paper-citation>。这种 <strong>“心中有数”</strong> 的能力，就是我们今天要讲的“世界模型”的雏形。</p> <h3 id="2-定义具身智能中的世界模型">2. 定义：具身智能中的世界模型</h3> <p>那么，在AI领域，特别是具身智能（Embodied AI）中，世界模型到底是什么？</p> <p>首先，具身智能要求代理感知复杂的多模态环境，在其中行动，并预测其行动将如何改变未来的世界状态 <alphaxiv-paper-citation title="Embodied AI Goal" page="1" first="EMBODIED AI aims" last="future world states"></alphaxiv-paper-citation>。</p> <p>在这个背景下，世界模型的核心定义是：一种<strong>内部模拟器</strong>（Internal Simulator）。它能够捕捉环境的动态变化，支持前向（Forward）和反事实（Counterfactual）的推演，从而服务于感知、预测和决策 <alphaxiv-paper-citation title="Core Definition" page="1" first="World models serve" last="decision making"></alphaxiv-paper-citation>。</p> <p><strong>关键区别点</strong>：请大家注意，这与我们常见的计算机视觉模型（如目标检测、语义分割）不同。世界模型侧重于生成可操作的预测，将其与静态场景描述符或纯生成视觉模型区分开来 <alphaxiv-paper-citation title="Distinction" page="1" first="This survey focuses" last="controllable dynamics."></alphaxiv-paper-citation>。</p> <h3 id="3-历史演变从rl到生成式ai">3. 历史演变：从RL到生成式AI</h3> <p>世界模型的发展并非一蹴而就，它经历了几个重要阶段：</p> <ol> <li> <strong>基于模型的强化学习 (Model-based RL)</strong>：早期研究根植于此，利用潜在的状态转移模型来提高样本效率和规划性能 <alphaxiv-paper-citation title="Early Origins" page="1" first="early AI research" last="planning performance"></alphaxiv-paper-citation>。</li> <li> <strong>里程碑式工作</strong>：Ha 和 Schmidhuber 在2018年的开创性工作正式确立了“世界模型”这一术语。随后，Dreamer 系列模型进一步强调了学习到的动力学如何驱动基于想象的策略优化 <alphaxiv-paper-citation title="Seminal Works" page="1" first="seminal work of" last="policy optimization."></alphaxiv-paper-citation>。</li> <li> <strong>通用模拟器时代</strong>：最近，随着大规模生成建模（如Sora, V-JEPA）的进步，世界模型已扩展到通用环境模拟器，不仅限于策略学习，还能进行高保真的未来预测 <alphaxiv-paper-citation title="Recent Expansion" page="1" first="More recently, advances" last="future prediction"></alphaxiv-paper-citation>。</li> </ol> <hr> <h2 id="核心分类学一-功能性与时间建模">核心分类学（一）—— 功能性与时间建模</h2> <p><strong>目标</strong>：深入解析世界模型的分类框架，重点讲解功能定位和时间维度上的预测机制。</p> <h3 id="1-综述提出的统一框架">1. 综述提出的统一框架</h3> <p>为了解决领域内术语混乱的问题，采用一种新的三轴分类法：(1) 功能性，(2) 时间建模，(3) 空间表示 <alphaxiv-paper-citation title="Taxonomy" page="1" first="propose a three-axis" last="Rendering Representation."></alphaxiv-paper-citation>。这不仅是分类工具，更是设计世界模型时的三个核心维度。</p> <h3 id="2-维度一功能性-functionality">2. 维度一：功能性 (Functionality)</h3> <p>根据设计目的，世界模型主要分为两类：</p> <ul> <li> <strong>决策耦合型 (Decision-Coupled)</strong>： <ul> <li>这类模型通常与具体的控制任务紧密结合。它们不仅预测未来，还直接参与策略（Policy）的训练。</li> <li>典型代表是Dreamer系列。其核心在于利用模型进行“想象中”的试错，从而减少在真实环境中的风险和采样成本。</li> </ul> </li> <li> <strong>通用目的型 (General-Purpose)</strong>： <ul> <li>这类模型更像是一个纯粹的物理引擎或视频生成器。它们的目标是尽可能真实地模拟环境，而不一定绑定特定的下游任务。</li> <li>例如Sora或V-JEPA，它们展示了强大的环境理解能力，可以作为通用的基础模型服务于各种下游应用。</li> </ul> </li> </ul> <h3 id="3-维度二时间建模-temporal-modeling">3. 维度二：时间建模 (Temporal Modeling)</h3> <p>环境是动态的，捕捉这种动态性至关重要。忠实地捕捉环境动态需要解决状态的时间演化问题 <alphaxiv-paper-citation title="Dynamics Requirement" page="1" first="Faithfully capturing environment" last="of scenes"></alphaxiv-paper-citation>。目前主流的方法有两种：</p> <ul> <li> <strong>序列模拟与推理 (Sequential Simulation and Inference)</strong>： <ul> <li>这是最直观的方法。模型一步步地推演：$t \to t+1 \to t+2$。</li> <li>这种方法符合因果律，非常适合实时控制和规划。但它面临的主要挑战是长视野推演中的误差累积 <alphaxiv-paper-citation title="Error Accumulation" page="1" first="Long-horizon rollouts" last="policy imagination"></alphaxiv-paper-citation>。如果第一步预测偏了一点，第100步可能就完全错误了。</li> </ul> </li> <li> <strong>全局差异预测 (Global Difference Prediction)</strong>： <ul> <li>有些模型不进行逐帧预测，而是预测一个较长时间段内的整体变化。这种方法在处理非因果任务或视频插帧时较为常见，但在实时控制中应用相对较少。</li> </ul> </li> </ul> <hr> <h2 id="核心分类学二-空间表示">核心分类学（二）—— 空间表示</h2> <p><strong>目标</strong>：这是最“硬核”的部分。探讨如何将复杂的3D物理世界压缩进神经网络中。</p> <h3 id="1-为什么空间表示如此重要">1. 为什么空间表示如此重要？</h3> <p>很多早期的世界模型只是在处理2D图像。但是，粗糙或以2D为中心的布局提供的几何细节不足以处理遮挡、物体恒常性和几何感知规划等挑战 <alphaxiv-paper-citation title="2D Limitations" page="1" first="coarse or 2D-centric" last="geometry-aware planning."></alphaxiv-paper-citation>。</p> <p>如果机器人要抓取杯子，它必须知道杯子的3D形状和位置，而不仅仅是像素颜色。</p> <h3 id="2-四种主流的空间表示法">2. 四种主流的空间表示法</h3> <p>根据这篇综述，我们将空间表示分为四类 <alphaxiv-paper-citation title="Spatial Taxonomy" page="1" first="Spatial Representation, Global" last="Rendering Representation."></alphaxiv-paper-citation>：</p> <ol> <li> <strong>全局潜在向量 (Global Latent Vector)</strong>： <ul> <li> <strong>原理</strong>：将整个图像压缩为一个极低维的向量（如VAE的瓶颈层）。</li> <li> <strong>优点</strong>：计算极快，适合快速规划。</li> <li> <strong>缺点</strong>：丢失了大量空间细节，无法处理复杂的物体交互。</li> </ul> </li> <li> <strong>Token 特征序列 (Token Feature Sequence)</strong>： <ul> <li> <strong>原理</strong>：类似于Transformer处理语言，将图像切成Patch，变成一串Token。</li> <li> <strong>优点</strong>：利用了Transformer强大的注意力机制，能捕捉长距离依赖。</li> <li> <strong>缺点</strong>：计算量大，且Token序列本身缺乏显式的3D几何结构。</li> </ul> </li> <li> <strong>空间潜在网格 (Spatial Latent Grid)</strong>： <ul> <li> <strong>原理</strong>：保留特征图的空间结构（如 $H \times W \times C$ 的特征图或3D体素）。</li> <li> <strong>优点</strong>：保留了局部性，对于卷积操作非常友好。相比于2D布局，体积或3D占用表示提供了更好的几何结构来支持预测和控制 <alphaxiv-paper-citation title="3D Benefits" page="1" first="volumetric or 3D" last="and control."></alphaxiv-paper-citation>。</li> </ul> </li> <li> <strong>分解式渲染表示 (Decomposed Rendering Representation)</strong>： <ul> <li> <strong>原理</strong>：这是最前沿的方向。结合了NeRF或3D Gaussian Splatting等图形学技术，将场景分解为对象、背景、光照等。</li> <li> <strong>意义</strong>：这使得世界模型不仅能预测“图像”，还能预测“3D结构”，实现了真正的物理一致性。</li> </ul> </li> </ol> <h3 id="3-总结">3. 总结</h3> <p>空间表示的选择往往决定了模型的上限。如果你只是想预测视频下一帧，Token序列可能够了；但如果你要让机器人做精细操作，空间潜在网格或分解式渲染可能是必须的。</p> <hr> <h2 id="应用领域与评估体系">应用领域与评估体系</h2> <p><strong>目标</strong>：了解世界模型在不同领域的实际表现，以及我们如何衡量它的好坏。</p> <h3 id="1-三大应用领域">1. 三大应用领域</h3> <p>综述系统化了跨机器人、自动驾驶和通用视频设置的数据资源和指标 <alphaxiv-paper-citation title="Domains" page="1" first="Systematize data resources" last="video settings"></alphaxiv-paper-citation>。</p> <ul> <li> <strong>机器人 (Robotics)</strong>： <ul> <li>关注点：操作（Manipulation）和移动（Locomotion）。</li> <li>难点：接触动力学（Contact Dynamics）很难模拟。</li> </ul> </li> <li> <strong>自动驾驶 (Autonomous Driving)</strong>： <ul> <li>关注点：安全性和长尾场景生成。</li> <li>应用：生成事故场景来训练感知算法，或者直接作为驾驶策略的大脑。有关自动驾驶的专门综述也有很多.</li> </ul> </li> <li> <strong>通用视频 (General Video)</strong>： <ul> <li>关注点：高分辨率、高帧率、视觉逼真度。</li> <li>现状：Sora等模型展示了惊人的物理一致性涌现能力。</li> </ul> </li> </ul> <h3 id="2-评估指标不仅仅是psnr">2. 评估指标：不仅仅是PSNR</h3> <p>我们要如何评价一个世界模型的好坏？仅仅看生成的视频清不清晰是不够的。</p> <ul> <li> <strong>像素预测质量 (Pixel Prediction Quality)</strong>： <ul> <li>指标：PSNR, SSIM, FID。</li> <li>局限：一个模糊但物理正确的预测，可能比一个清晰但违反物理定律的预测得分更低。</li> </ul> </li> <li> <strong>状态级理解 (State-level Understanding)</strong>： <ul> <li>指标：预测的物体位置、速度误差。</li> <li>适用：仅适用于有Ground Truth状态的仿真环境。</li> </ul> </li> <li> <strong>任务性能 (Task Performance)</strong>： <ul> <li> <strong>这是终极标准</strong>。如果一个世界模型能帮助强化学习Agent拿到更高的分数，那么即便它生成的画面像“马赛克”，它也是一个好的世界模型。</li> </ul> </li> </ul> <hr> <h2 id="挑战未来与总结">挑战、未来与总结</h2> <p><strong>目标</strong>：探讨当前技术的瓶颈，激发兴趣。</p> <h3 id="1-关键开放挑战">1. 关键开放挑战</h3> <p>根据综述，目前主要面临三大挑战 <alphaxiv-paper-citation title="Open Challenges" page="1" first="distill key open" last="error accumulation."></alphaxiv-paper-citation>：</p> <ol> <li> <strong>数据与评估的缺失</strong>： <ul> <li>我们需要统一的数据集，以及能够评估<strong>物理一致性</strong>而非仅仅是像素保真度的指标 <alphaxiv-paper-citation title="Metric Challenge" page="1" first="evaluation metrics that" last="pixel fidelity"></alphaxiv-paper-citation>。目前的指标太偏向视觉效果了。</li> </ul> </li> <li> <strong>性能与效率的权衡</strong>： <ul> <li>这是一个经典的工程问题：模型性能与实时控制所需的计算效率之间的权衡 <alphaxiv-paper-citation title="Efficiency Tradeoff" page="1" first="trade-off between model" last="real-time control"></alphaxiv-paper-citation>。Sora生成一分钟视频可能需要几十分钟渲染，这显然不能用于控制每秒需要做10次决策的机器人。</li> </ul> </li> <li> <strong>长视野一致性</strong>： <ul> <li>这是核心建模难点：实现长视野的时间一致性，同时减轻误差累积 <alphaxiv-paper-citation title="Consistency Challenge" page="1" first="modeling difficulty of" last="error accumulation."></alphaxiv-paper-citation>。如何让模型在“想象”未来10秒时，不会把车子“想”没了，或者把路“想”歪了？</li> </ul> </li> </ol> <h3 id="2-未来展望">2. 未来展望</h3> <ul> <li> <strong>物理感知的增强</strong>：未来的模型会更多地结合3D几何先验（如3D Gaussians）。</li> <li> <strong>多模态融合</strong>：不仅仅是视觉，还要结合触觉、听觉甚至语言。</li> <li> <strong>Sim-to-Real</strong>：如何将在模拟器中训练的世界模型无缝迁移到真实机器人上。</li> </ul> <h3 id="3-总结-1">3. 总结</h3> <p>今天我们系统地学习了具身智能中的世界模型。我们从认知科学的源头出发，了解了它作为“内部模拟器”的本质。我们通过功能性、时间建模和空间表示这三个轴，解构了当前最先进的模型架构。</p> <p>最后，我想引用综述中的观点：世界模型不仅是预测未来的工具，更是通向通用人工智能（AGI）的重要基石。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/DriveJEPA/">DriveJEPA</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/C_RADIOv4/">C_RADIOv4</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/VLM4VLA/">VLM4VLA</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 P W Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>