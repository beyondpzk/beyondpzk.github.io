<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> JEPA_WM | Tenacious life, proud journey. </title> <meta name="author" content="P W Name"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://beyondpzk.github.io/blog/2025/JEPA_WM/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Tenacious life, proud journey. </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">JEPA_WM</h1> <p class="post-meta"> Created on December 30, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>[TOC]</p> <h1 id="jepa_wm">JEPA_WM</h1> <p><a href="https://arxiv.org/pdf/2512.24497" rel="external nofollow noopener" target="_blank">paper链接</a></p> <h1 id="机器人学习与世界模型进阶专题">机器人学习与世界模型进阶专题</h1> <p><strong>核心论文：</strong> Terver et al., <em>What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?</em> (arXiv:2512.24497v2)</p> <hr> <p><strong>目标：</strong> 我们将超越世界模型（World Models）理论层面的“是什么”，深入探讨工程层面的“怎么做”。我们将对应用于机器人规划的<strong>联合嵌入预测架构（JEPA）</strong>进行拆解。与那些提出单一新颖架构的论文不同，这项工作进行了一项极其严谨的<strong>消融实验（Ablation Study）</strong>，旨在找出构建此类模型的最佳“配方”。</p> <p><strong>核心学习成果：</strong></p> <ol> <li>理解用于物理规划的 JEPA-WM 范式。</li> <li>分析关键设计选择：编码器选择、上下文长度和本体感觉（Proprioception）。</li> <li>评估潜空间中的规划算法（CEM 对比 梯度下降）。</li> <li>理解模型扩展性（Scaling）在“仿真到现实（Sim-to-Real）”鸿沟中的差异。</li> </ol> <hr> <h2 id="第一部分范式转变从像素到潜空间规划"><strong>第一部分：范式转变——从像素到潜空间规划</strong></h2> <h3 id="11-背景为什么要用世界模型"><strong>1.1 背景：为什么要用世界模型？</strong></h3> <p>在强化学习（RL）中，我们经常受困于样本效率问题。无模型（Model-Free）RL 需要数百万次交互。基于模型的 RL（MBRL）试图通过学习环境动力学来解决这个问题。</p> <p>然而，传统的 MBRL 在高维视觉空间（像素级）中往往表现不佳，因为预测每一个像素既昂贵又容易受到“噪声”干扰（例如，预测墙壁的确切纹理，而不是门的位置）。</p> <p>本文关注一种解决方案：<strong>在学习到的表征空间中进行规划</strong>，具体使用的是 <strong>JEPA-WMs</strong>。这类方法的核心在于抽象掉无关的细节，从而产生更高效的规划。 <alphaxiv-paper-citation title="Introduction" page="1" first="Planning is commonly" last="efficient planning."></alphaxiv-paper-citation></p> <h3 id="12-架构jepa-wm"><strong>1.2 架构：JEPA-WM</strong></h3> <p>让我们将系统形式化。我们预测的不是 $s_{t+1}$（像素），而是 $z_{t+1}$（潜变量）。</p> <p><strong>核心组件：</strong></p> <ol> <li> <strong>编码器（$E_{\phi, \theta}$）：</strong> 将观测值（$o_t$）映射为潜状态（$z_t$）。</li> <li> <strong>预测器（$P_\theta$）：</strong> 动力学模型。它接收当前状态和动作，预测<em>下一个</em>潜状态。</li> <li> <strong>规划器（Planner）：</strong> 这不是神经网络，而是一种算法（如 MPC），利用预测器来寻找最优动作序列。</li> </ol> <p>论文清晰地定义了这个框架：(编码器,预测器)就是我们所说的<strong>世界模型</strong>。 <alphaxiv-paper-citation title="Definitions" page="2" first="The encoder/predictor pair" last="world model."></alphaxiv-paper-citation></p> <h3 id="13-训练循环teacher-forcing"><strong>1.3 训练循环（Teacher-Forcing）</strong></h3> <p>如果在不使用重建损失（像素误差）的情况下训练？我们使用联合嵌入（Joint-Embedding）方法。</p> <ul> <li> <strong>输入：</strong> 过去的观测和动作的上下文。</li> <li> <strong>目标：</strong> <em>实际</em>未来状态的嵌入（由目标编码器计算得出）。</li> <li> <strong>损失：</strong> 潜空间中的距离（L2 或 L1）。</li> </ul> <p>训练过程涉及一个预测器，它接收过去观测和动作的上下文，并在时间步上并行预测下一个状态嵌入。 <alphaxiv-paper-citation title="Training" page="2" first="which is fed" last="state embedding."></alphaxiv-paper-citation></p> <hr> <h2 id="第二部分成功的要素系统特征分析"><strong>第二部分：成功的“要素”——系统特征分析</strong></h2> <h3 id="21-眼睛编码器的选择dino-vs-其他"><strong>2.1 眼睛：编码器的选择（DINO VS 其他）</strong></h3> <p>如果你想让机器人抓起一个杯子，它需要理解背后墙壁的纹理吗？不需要。它需要的是物体恒常性和分割能力。</p> <p><em>发现：</em> 论文将 DINOv2（自监督 ViT）与 V-JEPA 编码器进行了比较。 <em>结果：</em> <strong>DINO 获胜。</strong> 为什么？DINO 拥有更优越的细粒度物体分割能力。这对于精确的定位任务至关重要。 <alphaxiv-paper-citation title="Encoder Analysis" page="9" first="DINO has better" last="segmentation capabilities,"></alphaxiv-paper-citation></p> <h3 id="22-身体本体感觉proprioception"><strong>2.2 身体：本体感觉（Proprioception）</strong></h3> <p><em>讨论：</em> 我们应该仅仅依赖视觉（像素），还是让机器人知道它的关节角度？</p> <ul> <li> <strong>观察：</strong> 在许多“纯像素”论文中，为了使模型显得“通用”，往往忽略了本体感觉。</li> <li> <strong>论文结果：</strong> 结合本体感觉训练的模型表现始终更好。没有它，机械臂往往会在目标周围震荡，因为仅凭视觉缺乏精细运动停止所需的精度。 <alphaxiv-paper-citation title="Proprioception" page="8" first="models trained with" last="consistently better"></alphaxiv-paper-citation> </li> </ul> <h3 id="23-大脑预测器上下文与架构"><strong>2.3 大脑：预测器上下文与架构</strong></h3> <p>模型需要多少历史信息？</p> <ul> <li>$W=1$（1帧）：模型无法推断速度。</li> <li>$W=2$（2帧）：模型可以推断速度（$p_t - p_{t-1}$）。</li> <li> <p>$W=3$（3帧）：模型可以推断加速度。</p> </li> <li> <p><strong>关键发现：</strong> $W=1$ 和 $W=2$ 之间存在巨大的性能差距。速度信息是必不可少的。然而，过长的上下文（如 $W=7$）在仿真中反而会降低性能（过拟合/噪声）。有趣的是，真实世界数据（DROID）受益于稍长的上下文（$W=5$），这可能是由于真实物理动力学的复杂性。 <alphaxiv-paper-citation title="Context Length" page="8" first="gap between models" last="infer velocity."></alphaxiv-paper-citation></p> </li> <li> <strong>条件化（Conditioning）：</strong> 我们如何将动作 $a_t$ 输入到 Transformer 预测器中？ <ul> <li> <em>拼接（Concatenation）？</em> 简单。</li> <li> <em>AdaLN（自适应层归一化）？</em> 复杂但精细。</li> <li> <em>结果：</em> <strong>带 RoPE 的 AdaLN</strong> 平均表现最强，因为它将动作信息注入到<em>每一层</em>，防止了信号消失。 <alphaxiv-paper-citation title="Architecture" page="9" first="AdaLN with RoPE" last="average performance,"></alphaxiv-paper-citation> </li> </ul> </li> </ul> <h3 id="24-训练目标多步展开multistep-rollout"><strong>2.4 训练目标：多步展开（Multistep Rollout）</strong></h3> <p>如果我们只训练 $t \to t+1$，当我们规划 $t+10$ 时，模型可能会发生漂移。</p> <ul> <li> <strong>技术：</strong> 在训练期间增加未来多步的损失项。</li> <li> <strong>结果：</strong> 2步展开（2-step rollout）的损失是最佳的。超过这个步数（例如6步）会降低仿真中的性能，使模型对即时预测任务的专业性下降。 <alphaxiv-paper-citation title="Rollout Loss" page="8" first="performance increases when" last="rollout loss models,"></alphaxiv-paper-citation> </li> </ul> <hr> <h2 id="第三部分规划算法与真实世界迁移"><strong>第三部分：规划算法与真实世界迁移</strong></h2> <h3 id="31-优化问题"><strong>3.1 优化问题</strong></h3> <p>(之前ATOM的算法是不是就有用了?)</p> <p>一旦我们有了训练好的世界模型，我们需要解以下方程： \(a_{t:t+H}^* = \arg\min_{a} \sum_{k=t}^{t+H} \text{Cost}(\hat{z}_k, z_{goal})\)</p> <p>论文比较了三大类规划器：</p> <ol> <li> <strong>CEM（交叉熵方法）：</strong> 基于采样的。采样高斯动作，挑选最好的，重新拟合高斯分布。</li> <li> <strong>GD（梯度下降）：</strong> 通过学习到的模型反向传播误差，直接更新动作。</li> <li> <strong>Nevergrad (NG)：</strong> 一个无梯度优化库。</li> </ol> <h3 id="32-为什么梯度下降gd会失败"><strong>3.2 为什么梯度下降（GD）会失败？</strong></h3> <p>理论直觉表明 GD 应该是最好的，因为我们有一个可微的世界模型。</p> <ul> <li> <strong>现实检验：</strong> GD 在导航任务（迷宫/墙壁）上表现糟糕。</li> <li> <strong>原因：</strong> 潜空间中的成本曲面是非凸的，且充满局部极小值（例如，卡在墙边）。GD 无法“跳过”高成本的障碍。</li> <li> <strong>赢家：</strong> CEM（L2 距离）仍然是稳健的冠军。它的探索能力更强。 <alphaxiv-paper-citation title="Planning Optimizers" page="8" first="CEM L2" last="outperforms L1 cost."></alphaxiv-paper-citation> </li> </ul> <h3 id="33-扩展定律的差异仿真-vs-现实"><strong>3.3 扩展定律的差异（仿真 vs 现实）</strong></h3> <p>这是现代 AI 的重要一课。</p> <ul> <li> <strong>仿真（Metaworld）：</strong> 增加模型大小（ViT-S 到 ViT-L）<strong>没有</strong>帮助。物理很简单；小模型就已经让任务饱和了。</li> <li> <strong>真实世界（DROID）：</strong> 增加模型大小<strong>确实</strong>有帮助。真实世界的图像和动力学包含“偶然不确定性（aleatoric uncertainty）”和复杂性，需要更大的容量。</li> <li> <strong>结论：</strong> 不要为了简单的基准测试浪费算力去扩展模型。要为了现实世界而扩展。 <alphaxiv-paper-citation title="Scaling" page="9" first="simulated environments saturate" last="lower capacities."></alphaxiv-paper-citation> </li> </ul> <hr> <h2 id="第四部分综合与黄金配方"><strong>第四部分：综合与“黄金配方”</strong></h2> <h3 id="41-提议的最佳方案"><strong>4.1 提议的最佳方案</strong></h3> <p>基于研究，作者提出了一种特定的配置，击败了基线模型（DINO-WM, V-JEPA-2-AC）。</p> <p><strong>配方：</strong></p> <ul> <li> <strong>编码器：</strong> DINOv2（若追求照片级真实感可用 v3）。</li> <li> <strong>预测器：</strong> 带 AdaLN 条件化的 ViT。</li> <li> <strong>训练：</strong> 启用本体感觉 + 2步展开损失（2-step rollout loss）。</li> <li> <strong>规划：</strong> 使用 L2 距离的 CEM。</li> </ul> <p><strong>性能：</strong> 这种特定组合显著优于先前的 SOTA。例如，在“Reach（到达）”任务中，他们实现了高得多的成功率。 <alphaxiv-paper-citation title="Results" page="10" first="outperform DINO-WM and" last="most environments."></alphaxiv-paper-citation></p> <h3 id="42-讨论"><strong>4.2 讨论</strong></h3> <ol> <li> <strong>“奖励”难题：</strong> 本文使用目标图像（$z_g$）。如果任务没有目标的具体照片（例如，“尽可能快地跑”），如何调整这个 JEPA-WM？</li> <li> <strong>潜空间漂移：</strong> 即使有2步展开训练，模型在长时域（50+步）上也可能漂移。为什么 MPC（模型预测控制）能缓解这个问题？（提示：每一步都重新规划）。</li> <li> <strong>语言的角色：</strong> 论文提到了 VLA（视觉-语言-动作）模型。我们如何将 JEPA 预测器的条件改为文本指令而不是目标图像？</li> </ol> <hr> <p>这是为您准备的课堂讨论问题参考答案。作为教授，我不仅提供了标准答案，还加入了一些基于论文原理的延伸思考，以便您引导学生深入讨论。</p> <hr> <h3 id="问题-1奖励难题"><strong>问题 1：“奖励”难题</strong></h3> <p><strong>问题：</strong> 本文使用目标图像（$z_g$）作为导航终点，计算 $Cost = ||\hat{z}_t - z_g||$。如果任务没有目标的具体照片（例如“尽可能快地跑”或“保持直立”），你将如何调整这个 JEPA-WM？</p> <p><strong>参考答案：</strong> 我们需要将“目标距离”替换为一个<strong>学习到的奖励函数（Learned Reward Function）</strong>。</p> <ol> <li> <strong>方法：</strong> 我们可以在 JEPA 的预测器或编码器之上训练一个轻量级的多层感知机（MLP），记为 $R(z_t)$。</li> <li> <strong>训练：</strong> 使用带标注的数据集（或者通过人工反馈 RLHF）来训练这个 MLP，使其输入一个潜状态 $z_t$，输出一个标量值（Reward）。例如，如果任务是奔跑，输入当前状态的 $z$，输出当前的速度估算值。</li> <li> <strong>规划：</strong> 在规划阶段（CEM），我们不再最小化与目标图像的距离，而是最大化预测轨迹的累积奖励：$\max \sum R(\hat{z}_t)$。</li> <li> <strong>延伸思考：</strong> 这实际上让 JEPA-WM 从“目标条件化规划”转向了更通用的“基于模型的强化学习（MBRL）”。虽然这增加了训练奖励模型的开销，但大大扩展了模型的适用范围。</li> </ol> <hr> <h3 id="问题-2潜空间漂移与-mpc"><strong>问题 2：潜空间漂移与 MPC</strong></h3> <p><strong>问题：</strong> 即使有2步展开训练（2-step rollout），模型在长时域（如预测50步以上）上也必然会产生累积误差（漂移）。为什么 <strong>MPC（模型预测控制）</strong> 机制能缓解这个问题？</p> <p><strong>参考答案：</strong> 关键在于 MPC 的 <strong>“闭环反馈”</strong>机制，它并没有完全信任长期的预测。</p> <ol> <li> <strong>执行逻辑：</strong> 虽然我们在大脑中规划了未来 H 步（例如50步），但 MPC <strong>只执行第一个动作</strong> $a_t$。</li> <li> <strong>重置误差：</strong> 执行完 $a_t$ 后，机器人会通过传感器看到<strong>真实的</strong>新状态 $o_{t+1}$。此时，我们将编码器重新应用于真实的 $o_{t+1}$ 得到真实的 $z_{t+1}$。</li> <li> <strong>重新规划：</strong> 下一轮规划从真实的 $z_{t+1}$ 开始，而不是从模型预测的（可能带有误差的）$\hat{z}_{t+1}$ 开始。</li> <li> <strong>结论：</strong> MPC 每一步都用真实的观测值“校准”了当前位置。这就像使用 GPS 导航：虽然它规划了全程路线，但如果你偏离了路线，它会根据你当前的<strong>真实位置</strong>重新计算，而不是假设你还在原来的路线上盲目指挥。</li> </ol> <hr> <h3 id="问题-3语言的角色"><strong>问题 3：语言的角色</strong></h3> <p><strong>问题：</strong> 论文提到了 VLA（视觉-语言-动作）模型。我们如何将 JEPA 预测器的条件改为文本指令（如“拿起蓝色杯子”）而不是目标图像？</p> <p><strong>参考答案：</strong> 这涉及到<strong>多模态对齐（Multimodal Alignment）</strong>或<strong>条件注入（Condition Injection）</strong>。主要有两种改法：</p> <p><strong>方案 A：潜在空间对齐（CLIP 风格）</strong></p> <ul> <li> <strong>原理：</strong> 使用像 CLIP 这样预训练好的模型，它能将图像和文本映射到同一个共享空间。</li> <li> <strong>操作：</strong> <ol> <li>将指令“拿起蓝色杯子”通过文本编码器编码为向量 $e_{text}$。</li> <li>我们训练 JEPA 的视觉编码器，使其输出的 $z$ 与 CLIP 的空间对齐。</li> <li> <table> <tbody> <tr> <td>规划目标变为最小化当前状态与文本嵌入的距离：$Cost =</td> <td> </td> <td>\hat{z}<em>t - e</em>{text}</td> <td> </td> <td>$。</td> </tr> </tbody> </table> </li> </ol> </li> <li> <strong>优点：</strong> 不需要修改预测器架构。</li> </ul> <p><strong>方案 B：预测器条件化（Cross-Attention）</strong></p> <ul> <li> <strong>原理：</strong> 将文本指令作为一种“上下文”输入给预测器，告诉预测器“在这种意图下，世界会如何演变”。</li> <li> <strong>操作：</strong> <ol> <li>在预测器（Predictor）的 Transformer 架构中插入<strong>交叉注意力层（Cross-Attention Layers）</strong>。</li> <li>Query 是当前的状态 $z_t$，Key/Value 是文本指令的嵌入。</li> <li>这样，预测器不仅仅是在预测物理规律，而是在预测“为了实现该指令”而产生的状态变化。</li> </ol> </li> <li> <strong>论文关联：</strong> 论文中提到的 AdaLN（自适应层归一化）其实就是一种条件注入方式。我们可以把注入“动作”的地方，改为注入“动作 + 文本嵌入”，让模型根据语言指令来调节动力学预测。</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/DriveJEPA/">DriveJEPA</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/C_RADIOv4/">C_RADIOv4</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/GeRo/">GeRo</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 P W Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>