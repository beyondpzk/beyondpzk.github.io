<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> AutoVLA | Tenacious life, proud journey. </title> <meta name="author" content="P W Name"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?v=6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://beyondpzk.github.io/blog/2025/AutoVLA/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Tenacious life, proud journey. </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">AutoVLA</h1> <p class="post-meta"> Created on June 16, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/vla"> <i class="fa-solid fa-tag fa-sm"></i> VLA</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>[TOC]</p> <h1 id="autovla">AutoVLA</h1> <p><a href="https://arxiv.org/abs/2506.13757" rel="external nofollow noopener" target="_blank">paper link</a></p> <hr> <h1 id="autovla--通用视觉-语言-动作模型的端到端自动驾驶">AutoVLA —— 通用视觉-语言-动作模型的端到端自动驾驶</h1> <p><strong>课程性质</strong>：深度研讨课 (Advanced Seminar) <strong>授课时长</strong>：3-5 小时 <strong>主讲人</strong>：[您的名字] 教授 <strong>目标受众</strong>：计算机科学/人工智能方向 高年级本科生及研究生 <strong>预备知识</strong>：Transformer架构、强化学习基础（PPO/DPO）、自动驾驶基础模块（感知/规划）。</p> <hr> <h2 id="第一部分背景与动机-introduction--motivation">第一部分：背景与动机 (Introduction &amp; Motivation)</h2> <h3 id="11-自动驾驶范式的演进">1.1 自动驾驶范式的演进</h3> <p>在深入论文细节之前，先回顾自动驾驶技术栈的演进逻辑。</p> <ul> <li> <strong>模块化范式 (Modular Paradigm)</strong>：传统的自动驾驶系统（如Waymo早期的系统）将任务分解为感知（Perception）、预测（Prediction）、规划（Planning）和控制（Control）。 <ul> <li> <em>优点</em>：可解释性强，易于调试。</li> <li> <em>缺点</em>：误差累积（Error Propagation），各模块目标函数不一致，缺乏全局优化。</li> </ul> </li> <li> <strong>端到端范式 (End-to-End Paradigm)</strong>：从原始传感器输入直接映射到控制信号（或轨迹）。 <ul> <li> <em>现状</em>：早期的端到端模型（如UniAD, VAD）主要基于模仿学习（Imitation Learning），虽然在闭环测试中表现出色，但缺乏“常识”和“推理能力”。它们擅长拟合数据分布，但面对长尾场景（Corner Cases）时往往不知所措。</li> </ul> </li> </ul> <h3 id="12-视觉-语言模型-vlm-的引入与挑战">1.2 视觉-语言模型 (VLM) 的引入与挑战</h3> <p>近年来，GPT-4V, Qwen-VL等大模型的出现，为引入“世界知识”提供了可能。我们称之为 <strong>Vision-Language-Action (VLA)</strong> 模型。然而，现有的VLA在驾驶领域面临两大核心痛点：</p> <ol> <li> <strong>动作生成的非物理性 (Physically-infeasible Actions)</strong>： <ul> <li>如果直接让LLM输出文本描述（如“左转，速度5m/s”），由于语言空间的离散性和模糊性，很难保证生成的轨迹符合车辆动力学约束。</li> <li>部分工作使用中间元动作（Meta-actions），但这破坏了完全的端到端微分特性。</li> </ul> </li> <li> <strong>推理的低效性 (Inefficient Reasoning)</strong>： <ul> <li>目前的VLM驱动驾驶模型往往采用“思维链”（Chain-of-Thought, CoT）进行推理。</li> <li> <em>问题</em>：并不是所有场景都需要深思熟虑。在空旷的直道上行驶，人类依靠的是“直觉”（System 1）；而在复杂的路口博弈，人类才使用“逻辑推理”（System 2）。现有的模型往往被迫在所有场景下都进行冗长的推理，导致推理延迟高，无法满足实时性要求。</li> </ul> </li> </ol> <h3 id="13-autovla-的核心贡献">1.3 AutoVLA 的核心贡献</h3> <p>本篇论文提出的 <strong>AutoVLA</strong> 正是为了解决上述问题。请大家记住它的三个核心关键词：</p> <ol> <li> <strong>物理动作Token化 (Physical Action Tokenization)</strong>：将连续轨迹离散化为Token，直接嵌入语言模型的词表中。</li> <li> <strong>双思维模式 (Dual Thinking Modes)</strong>：受Daniel Kahneman《思考，快与慢》启发，模型具备“快思考”（直接输出动作）和“慢思考”（先推理后动作）的能力。</li> <li> <strong>强化微调 (Reinforcement Fine-Tuning, RFT)</strong>：利用 <strong>GRPO</strong> 算法，不仅优化驾驶性能，还通过奖励函数自动学会在何种场景下应该“思考”，在何种场景下应该“直觉反应”。</li> </ol> <hr> <h2 id="第二部分autovla-模型架构详解-model-architecture">第二部分：AutoVLA 模型架构详解 (Model Architecture)</h2> <h3 id="21-整体架构概览">2.1 整体架构概览</h3> <p>AutoVLA 是一个统一的自回归生成模型（Unified Autoregressive Generation Model）。</p> <ul> <li> <strong>Backbone</strong>: 选用 <strong>Qwen2.5-VL-3B</strong>。 <ul> <li>为什么选3B？这是为了在车载边缘计算设备上实现部署的可能性，同时Qwen系列在视觉理解上表现优异。</li> </ul> </li> <li> <strong>输入模态 (Inputs)</strong>: <ol> <li> <strong>多视角视频流</strong> $C$：前视、左前、右前。每个视角包含当前帧及过去3帧（共4帧，2Hz），捕捉时序信息。</li> <li> <strong>文本指令</strong> $I$：如 “Turn Left”, “Go Straight”。</li> <li> <strong>自车状态</strong> $S$：速度、加速度、历史动作。</li> <li> <strong>System Prompt</strong>：定义任务角色和输出格式。</li> </ol> </li> </ul> <h3 id="22-核心创新动作空间的离散化-action-tokenization">2.2 核心创新：动作空间的离散化 (Action Tokenization)</h3> <p>LLM擅长处理离散Token，而驾驶轨迹是连续的。如何桥接？AutoVLA 并没有外接一个MLP解码器，而是<strong>扩充了LLM的词表</strong>。</p> <ol> <li> <strong>轨迹定义</strong>: 轨迹 $P \in \mathbb{R}^{\tau \times d}$ 被切分为一系列短时片段。</li> <li> <strong>动作Token</strong>: 每个Token $a_t$ 代表 0.5秒 内的车辆位移和航向变化 $(\Delta x, \Delta y, \Delta \theta)$。</li> <li> <strong>码本构建 (Codebook Construction)</strong>: <ul> <li>使用 <strong>Waymo Open Motion Dataset (WOMD)</strong> 中的真实轨迹数据。</li> <li>算法：<strong>K-disk Clustering</strong>（一种改进的K-means，保证覆盖空间的多样性）。</li> <li>最终得到 $K=2048$ 个离散的动作Token。</li> <li> <em>在词表中表示</em>：<code class="language-plaintext highlighter-rouge">&lt;action_0&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;action_1&gt;</code>, …, <code class="language-plaintext highlighter-rouge">&lt;action_2047&gt;</code>。</li> </ul> </li> </ol> <p><strong>解码过程</strong>: 模型直接自回归地输出： \(\text{Output Sequence} = [\underbrace{l_1, l_2, \dots, l_L}_{\text{Reasoning Text}}, \underbrace{a_1, a_2, \dots, a_T}_{\text{Action Tokens}}]\) 这些 $a_t$ 随后通过查表（Look-up Table）映射回物理空间的 $(\Delta x, \Delta y, \Delta \theta)$，并通过累积计算还原为全局轨迹。</p> <h3 id="23-统一推理与动作生成">2.3 统一推理与动作生成</h3> <p>AutoVLA 不仅是规划器，也是推理器。它支持两种模式的输出，这取决于System Prompt的引导以及模型学到的策略：</p> <ul> <li> <strong>Fast Thinking (直觉)</strong>: <ul> <li>输出：<code class="language-plaintext highlighter-rouge">[Start] -&gt; &lt;action_i&gt; -&gt; &lt;action_j&gt; ...</code> </li> <li>特点：低延迟，适用于简单场景（如跟车、直行）。</li> </ul> </li> <li> <strong>Slow Thinking (推理)</strong>: <ul> <li>输出：<code class="language-plaintext highlighter-rouge">[Start] -&gt; &lt;think&gt; Scene Description... Critical Objects... Intent... &lt;/think&gt; -&gt; &lt;answer&gt; &lt;action_i&gt; ... &lt;/answer&gt;</code> </li> <li>特点：包含完整的CoT过程，适用于复杂博弈场景，但推理耗时增加。</li> </ul> </li> </ul> <hr> <h2 id="第三部分训练策略-training-methodology">第三部分：训练策略 (Training Methodology)</h2> <p>AutoVLA 的训练分为两个阶段：监督微调 (SFT) 和 强化微调 (RFT)。这部分包含了论文最精彩的工程与算法设计。</p> <h3 id="31-推理数据生成-reasoning-data-generation">3.1 推理数据生成 (Reasoning Data Generation)</h3> <p>没有现成的大规模高质量驾驶推理数据集。作者构建了一个自动化流水线：</p> <ul> <li> <strong>Teacher Model</strong>: Qwen2.5-VL-72B (强大的多模态大模型)。</li> <li> <strong>Student Model</strong>: AutoVLA (3B)。</li> <li> <strong>Prompt Engineering</strong>: 强制Teacher模型遵循四个步骤进行标注： <ol> <li> <strong>场景描述</strong> (Scene Description)</li> <li> <strong>关键物体识别</strong> (Critical Object Identification)</li> <li> <strong>意图推理</strong> (Reasoning on Intent)</li> <li> <strong>最终决策</strong> (Final Action Decision)</li> </ol> </li> <li> <strong>Hint</strong>: 将Ground Truth轨迹作为提示输入给Teacher，防止产生幻觉（Hallucination），确保推理逻辑是为了解释正确的动作。</li> <li> <strong>数据量</strong>: 约 45.6k (nuPlan) + 7.2k (Waymo) 条CoT标注数据。</li> </ul> <h3 id="32-阶段一监督微调-supervised-fine-tuning-sft">3.2 阶段一：监督微调 (Supervised Fine-Tuning, SFT)</h3> <p>目标是让模型学会基本的驾驶能力和推理格式。 损失函数由两部分组成：</p> <ol> <li> <strong>语言损失</strong> $\mathcal{L}_{LM}$: 标准的Next Token Prediction Loss。</li> <li> <strong>动作损失</strong> $\mathcal{L}_{action}$: 专门针对动作Token部分的预测损失。</li> </ol> <p>\(\mathcal{L}_{SFT} = w_i \cdot (\mathcal{L}_{LM} + \lambda_a \mathcal{L}_{action})\) 其中 $w_i$ 是样本权重，对于包含CoT的数据给予更高权重，以促进推理能力的学习。此时，模型虽然学会了CoT，但它不知道<strong>什么时候</strong>该用CoT。</p> <h3 id="33-阶段二强化微调-reinforcement-fine-tuning-rft">3.3 阶段二：强化微调 (Reinforcement Fine-Tuning, RFT)</h3> <p>这是论文的点睛之笔。为什么需要RL？</p> <ol> <li> <strong>指标不可微</strong>: 驾驶的好坏（如碰撞率、舒适度PDMS）无法直接通过梯度反向传播优化。</li> <li> <strong>效率权衡</strong>: 我们希望模型“该快则快，该慢则慢”。这需要一个奖励函数来惩罚不必要的慢思考。</li> </ol> <p><strong>算法选择: GRPO (Group Relative Policy Optimization)</strong></p> <ul> <li> <em>背景</em>: GRPO 是 DeepSeek-R1 背后的核心算法之一。</li> <li> <em>优势</em>: 相比PPO，GRPO<strong>不需要训练价值网络 (Critic)</strong>，大大减少了显存占用和训练复杂度。</li> <li> <em>核心逻辑</em>: 对同一个输入 $q$，采样一组输出 $G = {o_1, o_2, \dots, o_G}$。通过比较组内各个输出的奖励，计算优势（Advantage）。</li> </ul> <p><strong>目标函数</strong>: \(J_{GRPO}(\theta) = \mathbb{E} \left[ \frac{1}{G} \sum_{i=1}^G \left( \min \left( \frac{\pi_\theta(o_i|q)}{\pi_{\theta_{old}}(o_i|q)} A_i, \text{clip}(\dots) A_i \right) - \beta D_{KL}(\pi_\theta || \pi_{ref}) \right) \right]\) 其中优势 $A_i$ 是标准化的组内奖励： \(A_i = \frac{r_i - \text{mean}(\{r_j\})}{\text{std}(\{r_j\})}\)</p> <p><strong>奖励设计 (The Reward Function)</strong> 奖励函数决定了模型的行为倾向： \(r = r_{\text{Driving}} - \lambda_r r_{\text{CoT}}\)</p> <ol> <li> <strong>驾驶奖励 ($r_{\text{Driving}}$)</strong>: <ul> <li>在nuPlan中使用 <strong>PDMS (Predictive Driver Model Score)</strong>，这是一个综合考量安全性、舒适度和交通规则顺应性的指标。</li> <li>在Waymo中使用 <strong>ADE (Average Displacement Error)</strong> 的负值。</li> </ul> </li> <li> <strong>推理惩罚 ($r_{\text{CoT}}$)</strong>: <ul> <li>如果模型输出了 <code class="language-plaintext highlighter-rouge">&lt;think&gt;...&lt;/think&gt;</code> 标签，则给予一定的惩罚。</li> <li> <em>机制解释</em>: 这是一个博弈。如果“慢思考”带来的驾驶性能提升（$r_{\text{Driving}}$ 增加）能够抵消时间惩罚（$r_{\text{CoT}}$），模型就会选择慢思考；否则，模型会倾向于直接输出动作。这就是<strong>自适应推理 (Adaptive Reasoning)</strong> 的来源。</li> </ul> </li> </ol> <hr> <h2 id="第四部分实验结果分析-experiments--analysis">第四部分：实验结果分析 (Experiments &amp; Analysis)</h2> <h3 id="41-定量评估-quantitative-results">4.1 定量评估 (Quantitative Results)</h3> <p>实验在 nuPlan, nuScenes, Waymo 和 CARLA 四个主流基准上进行。</p> <ul> <li> <strong>nuPlan</strong>: 在Val14 benchmark上，AutoVLA取得了 <strong>80.54</strong> 的PDM Score，显著优于传统的规划器和之前的VLA模型。</li> <li> <strong>闭环测试 (Closed-loop)</strong>: 在nuPlan的闭环测试中，AutoVLA展现了极高的达成率（L1 Score 92.4%），证明了其策略的鲁棒性，不仅仅是开环拟合。</li> <li> <strong>RFT的效果</strong>: <ul> <li>对比SFT模型，经过RFT后，PDMS提升了约 <strong>10.6%</strong>。</li> <li> <strong>运行时间 (Runtime)</strong>: 平均推理时间减少了 <strong>66.8%</strong>。这说明模型在大量简单场景中成功切换到了“快思考”模式。</li> </ul> </li> </ul> <h3 id="42-定性分析-qualitative-analysis">4.2 定性分析 (Qualitative Analysis)</h3> <p>让我们看几个具体案例（参考论文Fig 1和Fig 5）：</p> <ul> <li> <strong>场景1（施工区域）</strong>: 前方有工人举着SLOW牌子，右侧有铲车。 <ul> <li> <em>模型行为</em>: 触发 <strong>Slow Thinking</strong>。推理文本识别出工人手势和障碍物，规划出一条向左变道并减速的轨迹。</li> </ul> </li> <li> <strong>场景2（空旷直道）</strong>: 天气晴朗，前方无车。 <ul> <li> <em>模型行为</em>: 触发 <strong>Fast Thinking</strong>。没有输出推理文本，直接输出了加速直行的动作Token。</li> <li> <em>对比</em>: 在RFT之前，SFT模型即使在这种简单场景下也会啰嗦地描述“天气晴朗，路面干燥…”，浪费了计算资源。</li> </ul> </li> </ul> <h3 id="43-扩展性研究-scaling-law">4.3 扩展性研究 (Scaling Law)</h3> <p>论文探究了数据量对性能的影响（Fig 4）。</p> <ul> <li>随着训练数据从10k增加到185k，性能持续提升。</li> <li>有趣的是，在小数据量下（&lt;50k），引入CoT反而可能损害性能（可能是因为模型通过死记硬背学会了格式但没学会逻辑）。但在大数据量下，CoT带来的增益非常明显，证明了推理能力的涌现需要数据规模支撑。</li> </ul> <hr> <h2 id="第五部分总结与讨论-summary--discussion">第五部分：总结与讨论 (Summary &amp; Discussion)</h2> <h3 id="51-核心结论">5.1 核心结论</h3> <p>AutoVLA 成功证明了将<strong>物理动作直接Token化</strong>并融入LLM是可行的。更重要的是，它展示了通过 <strong>GRPO</strong> 进行强化微调，可以有效地在<strong>性能（Safety）</strong>与<strong>效率（Efficiency）</strong>之间找到平衡点，实现了类似于人类的 System 1 / System 2 双重思维模式。</p> <h3 id="52-思考">5.2 思考</h3> <ol> <li> <strong>关于Tokenizer</strong>: K-disk聚类得到的2048个动作Token是否足够覆盖所有极端驾驶情况（如高速紧急避让的漂移）？如果不够，该如何改进？（提示：考虑连续回归头或者更细粒度的分层Codebook）。</li> <li> <strong>关于奖励函数</strong>: 目前的 $r_{\text{CoT}}$ 只是简单的惩罚长度。我们是否可以设计更精细的奖励，比如根据推理内容的质量（是否提到了关键风险物）来给予奖励，而不仅仅是长度？</li> <li> <strong>关于部署</strong>: 3B模型在车载端的实时性约为100ms（Fast mode）到1s（Slow mode）。在时速100km/h时，1s意味着车辆盲开了27米。如何进一步解决Slow Mode在高速场景下的安全性问题？（提示：并行计算、推测解码 Speculative Decoding）。</li> </ol> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/DriveJEPA/">DriveJEPA</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/C_RADIOv4/">C_RADIOv4</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/GeRo/">GeRo</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 P W Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?v=c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>