---
layout: post
title: Gato
date: 2022-05-12
categories: [VLA, EmbodiedAI]
toc:
    sidebar: left
    max_level: 4
---

[TOC]

# Gato: A Generalist Agent


[paper link](https://arxiv.org/abs/2205.06175) 


人工智能（AGI）发展史上具有里程碑意义的论文——由DeepMind团队在2022年发表的**《A Generalist Agent》**，也就是**Gato**。

这篇论文的重要性在于，它挑战了过去人工智能领域“专才专用”的范式，提出了一个激进的假设：**只要我们将不同模态的数据都序列化为Token，一个单一的Transformer网络就能同时学会玩Atari游戏、给图片写标题、甚至控制真实的机械臂。**


---

# 第一模块：设计哲学与通用智能的愿景

## 1.1 背景：从“专才”到“通才”的范式转移

在Gato之前，强化学习（RL）和机器人学（Robotics）领域的主流做法是为每个任务设计特定的架构。比如，处理图像我们用CNN，处理序列决策我们用LSTM或Transformer，处理控制我们设计特定的策略网络。虽然我们在单一任务上（如AlphaGo, OpenAI Five）取得了超越人类的成就，但这些系统是脆弱的，无法泛化。

Gato的灵感直接来源于大型语言模型（LLM）的成功。既然GPT-3可以通过“下一个Token预测”来处理翻译、写作、编程等多种任务，我们能否将这种通用的序列建模能力扩展到文本之外的领域？Gato的核心论点是：**如果我们将视觉、本体感觉（Proprioception）、关节力矩（Torques）都视为数据流，那么就可以训练一个单一的“通才”智能体。** <alphaxiv-paper-citation title="Abstract" page="1" first="Inspired by progress" last="of text outputs." />

## 1.2 核心假设：扩展定律在控制领域的应用

这篇论文不仅是一个工程壮举，它实际上是在测试一个科学假设：**通过扩大数据规模、计算量和模型参数，并持续拓宽训练分布，我们可以获得一个能够适应任何任务、行为和具身形式（Embodiment）的通用智能体。**

这与Sutton提出的“苦涩的教训（The Bitter Lesson）”不谋而合——从历史来看，那些能利用算力扩张的通用方法，最终总会战胜利用特定领域知识的特化方法。Gato在当时（2022年）选择了一个约12亿（1.2B）参数的模型规模，这个规模是为了保证在控制真实机器人时能满足实时性（Real-time control）的要求。 <alphaxiv-paper-citation title="Scaling Hypothesis" page="2" first="We hypothesize that" last="behaviors." />

## 1.3 训练范式：序列建模与监督学习

与其说Gato是一个强化学习模型，不如说它是一个在大规模轨迹数据上进行**监督学习（Supervised Learning）**的序列模型。它并没有在训练中通过与环境交互来最大化奖励（那是RL做的事），而是利用现有的专家策略产生的数据进行“行为克隆（Behavior Cloning, BC）”。

训练的目标非常单纯：给定一段历史上下文（Context），预测下一个Token。这个Token可能是一个文本词，可能是机器人的一个动作，也可能是一个离散的按键。这种统一的训练目标消除了针对特定领域设计归纳偏置（Inductive Biases）的需求。 <alphaxiv-paper-citation title="Training Paradigm" page="2" first="For simplicity Gato" last="supervised manner;" />

---

# 第二模块：数据的统一表示与Token化（Tokenization）

这是理解Gato最关键的技术细节。要让一个网络处理截然不同的模态，必须解决如何让图像、文本和关节力矩讲同一种“语言”。Gato的答案是：**一切皆为Token序列。**

## 2.1 文本与图像的Token化

文本的处理是标准的。Gato使用了SentencePiece编码，词表大小为32000，整数范围在 $[0, 32000)$。

对于图像，Gato借鉴了Vision Transformer (ViT) 的思路。图像被分割成互不重叠的 $16 \times 16$ 的图块（Patches）。这些图块按光栅顺序（Raster order）排列。每个图块内的像素值被归一化到 $[-1, 1]$ 并除以图块大小的平方根。 <alphaxiv-paper-citation title="Image Tokenization" page="3" first="Images are first" last="raster order," />

## 2.2 连续值的离散化：$\mu$-law 编码

机器人的本体感觉（如关节角度）和动作（如力矩）通常是连续浮点数。Transformer本质上是一个分类器，擅长处理离散符号。Gato如何处理连续值？

它采用了一种在音频处理（如WaveNet）中常用的技术：**$\mu$-law 压扩（Companding）**。首先将数据展平，然后通过以下公式将数值非线性地映射到 $[-1, 1]$ 区间：

$$F(x) = \text{sgn}(x) \frac{\ln(|x|\mu + 1.0)}{\ln(M\mu + 1.0)}$$

其中 $\mu=100$，$M=256$。这种编码方式对接近0的小数值有更高的分辨率，而对大数值的分辨率较低，非常适合人类感知和控制信号的特性。映射后，数值被离散化为1024个均匀的箱（bins），并平移到 $[32000, 33024)$ 的整数范围内，以避免与文本Token冲突。 <alphaxiv-paper-citation title="Continuous Values" page="3" first="Continuous values, e.g." last="uniform bins." />

## 2.3 序列排序（Sequencing）

有了Token，我们还需要定义它们的排列顺序。Gato定义了一个规范的序列顺序：

1.  **文本 Token**（按原始顺序）。
2.  **图像 Patch Token**（按光栅顺序）。
3.  **张量（Tensors）**（按行优先顺序）。
4.  **智能体的时间步（Timesteps）**：先是观测（Observation）Token，然后是一个分隔符（Separator）Token，最后是动作（Action）Token。

这种严格的排序保证了模型能够学习到时间上的因果关系。 <alphaxiv-paper-citation title="Sequence Ordering" page="3" first="After converting data" last="action tokens." />

---

# 第三模块：模型架构深度解析

Gato的骨架是一个**仅解码器（Decoder-only）的Transformer**。这意味着它和GPT系列一样，通过掩码注意力机制（Masked Attention）只能“看”到过去的信息。

## 3.1 总体架构参数

论文中主要实验使用的是一个1.18B参数的模型。具体的超参数如下：
*   **层数（Layers）**: 24层
*   **注意力头（Attention Heads）**: 16个
*   **嵌入维度（Embedding Size）**: 2048
*   **前馈网络隐藏层维度（FFN Hidden Size）**: 8196

这在LLM领域不算大，但在实时控制领域，这是一个相当庞大的网络，需要保证推理延迟足够低以便控制物理机器人。 <alphaxiv-paper-citation title="Model Size" page="4" first="Gato uses a" last="of 8196" />

## 3.2 嵌入函数（Embedding Function）

虽然主要架构是Transformer，但输入层并非全是简单的查表（Lookup Table）。为了高效处理多模态，$f(\cdot; \theta_e)$ 嵌入函数针对不同模态有不同的操作：

*   **文本、离散/连续观测值**：使用学习到的向量嵌入空间（Lookup Table）。
*   **图像 Patch**：这是关键点。图像Token不仅仅是查表，而是通过了一个**ResNet Block**。每个Patch通过这个ResNet块被编码成一个向量。这相当于在Transformer之前有一个轻量级的视觉编码器。 <alphaxiv-paper-citation title="Embedding Logic" page="4" first="Tokens belonging to" last="within-image position" />

具体到这个ResNet Block，它使用了V2架构，包含GroupNorm（32组）和GELU激活函数。 <alphaxiv-paper-citation title="ResNet Details" page="33" first="This block uses" last="activation functions." />

## 3.3 位置编码（Position Encodings）

对于序列模型，位置信息至关重要。Gato采用了两种位置编码策略：

1.  **局部位置编码（Local Position Encodings）**：针对同一时间步内的Token，根据它们在时间步内的局部位置添加编码。
2.  **图像块位置编码**：为了让模型理解图像的2D结构，模型通过Patch的归一化行、列坐标，分别查表得到行编码和列编码，并加到Patch的嵌入向量上。这是为了保留空间语义。 <alphaxiv-paper-citation title="Position Encodings" page="4" first="Learnable position encodings" last="encoding vector." />

## 3.4 损失函数（Loss Function）

训练的目标是最大化对数似然。对于一个批次 $B$，损失函数如下：

$$ \mathcal{L}(\theta, B) = - \sum_{b=1}^{|B|} \sum_{l=1}^{L} m(b, l) \log p_\theta(s_l^{(b)} | s_1^{(b)}, \dots, s_{l-1}^{(b)}) $$

这里引入了一个掩码函数 $m(b, l)$。这个掩码非常重要：**并不是所有的Token都会产生损失。** 只有文本Token和智能体的动作（Action）Token会被计算损失。图像Token和观测Token虽然作为上下文输入，但模型不需要预测它们（至少在这个版本的Gato中）。 <alphaxiv-paper-citation title="Training Loss" page="4" first="The training loss" last="and 0 otherwise." />

---

# 第四模块：实验设置与结果分析

Gato的训练数据规模庞大且多样，这决定了它的通用性。

## 4.1 数据集构成

Gato在约**604个不同的任务**上进行了训练。这些数据包括：
*   **模拟控制**：Atari游戏、DeepMind Control Suite、Meta-World等。
*   **视觉与语言**：MassiveText, ALIGN, MS-COCO等。
*   **机器人**：RGB Stacking（堆叠积木）任务，包含仿真和真实机器人数据。

特别值得注意的是，对于控制任务，Gato使用了过滤后的专家数据（Returns at least 80% of expert return），这保证了模型学到的是高质量的策略。 <alphaxiv-paper-citation title="Datasets" page="5" first="Gato was trained" last="specifications." />

## 4.2 模拟环境中的表现

结果令人印象深刻。在450个以上的任务中，Gato的性能超过了专家分数的50%。
*   **Atari**：在23个游戏中达到或超过人类平均水平。
*   **BabyAI**：在几乎所有关卡中达到专家分数的80%以上。
*   **Meta-World**：在44/45个任务中超过50%的成功率。

虽然在单任务比较上，专门训练的专家（Specialist）通常还是比Gato强，但Gato是用**同一套权重**解决了所有问题，这是质的飞跃。 <alphaxiv-paper-citation title="Simulated Performance" page="7" first="As shown in" last="expert score threshold." />

## 4.3 真实机器人控制（Real-world Robotics）

这是最具挑战性的部分。Gato通过观察图像和本体感觉，直接输出关节力矩来控制一个Sawyer机械臂进行积木堆叠（RGB Stacking）。

实验展示了Gato不仅在仿真中表现良好，还能直接迁移到真实机器人上。在“技能泛化（Skill Generalization）”测试中，Gato展现了与基线方法相当的能力。更重要的是，通过**微调（Fine-tuning）**，Gato可以迅速适应新的任务或从未见过的物体形状。 <alphaxiv-paper-citation title="Robotics Results" page="12" first="Gato, in both" last="the expert." />

## 4.4 提示（Prompting）与上下文学习

由于不同任务可能共享相同的观测空间（例如都是Atari画面），模型如何知道该玩哪个游戏？
Gato使用**提示（Prompting）**机制。在训练中，25%的序列会前置一段来自同一任务的演示（Demonstration）。在测试时，我们可以通过提供一段成功的演示作为Prompt，来告诉Gato我们想让它做什么。这类似于GPT-3的Few-shot prompting。 <alphaxiv-paper-citation title="Prompting" page="4" first="During evaluation, the" last="we present here." />

---

# 第五模块：批判性分析与未来展望


## 5.1 局限性

1.  **上下文长度限制**：Gato的上下文窗口只有1024个Token。对于高频控制任务，这可能只覆盖了几秒钟的历史。这限制了它处理需要长期记忆的复杂任务的能力。
2.  **遗忘灾难与容量**：虽然Gato是一个通用智能体，但在特定任务（如Atari）上，它仍然不如专门训练的智能体。论文中提到，专门训练的Atari智能体在更多游戏中超越了人类。这表明单一网络的容量（1.18B）可能还不足以完美容纳所有领域的知识。 <alphaxiv-paper-citation title="Specialist Comparison" page="14" first="The specialist Atari" last="23 games." />
3.  **缺乏在线学习**：Gato完全是离线训练（Offline Training）的。它没有在部署后通过试错来自我提升的机制。这意味着它无法应对训练分布之外的全新的、动态变化的环境，除非进行微调。

## 5.2 解释性分析

论文对模型的内部表示进行了可视化。
*   **注意力图（Attention Maps）**：显示模型能够关注到图像中与任务相关的物体（如球拍、积木）。
*   **嵌入可视化（t-SNE）**：不同任务的嵌入在空间中形成了清晰的聚类，甚至从未见过的任务（Hold-out tasks）也能被映射到语义相关的区域。这证明了模型学到了通用的表示，而不仅仅是死记硬背。 <alphaxiv-paper-citation title="Embeddings" page="15" first="Embeddings from the" last="to each other." />

## 5.3 对未来的启示

Gato证明了**“大一统模型（The One Big Net）”**在多模态控制领域的可行性。它通过序列建模统一了离散和连续、视觉和语言。

未来的研究方向可能包括：
1.  **扩大规模**：随着硬件进步，更大的模型（如10B+）可能会展现出更强的涌现能力。
2.  **统一训练目标**：结合离线预训练和在线强化学习（RL），让模型能在部署中持续进化。
3.  **世界模型**：不仅预测动作，还预测下一个观测（Video Prediction），这将使智能体具备规划（Planning）能力。


## 一个具体的training sample

在 Gato 的眼中，无论是莎士比亚的诗句、Atari 游戏的像素画面，还是机械臂的关节力度，本质上**没有任何区别**——它们全都是一串**整数（Integers）**。

为了直观理解，构造一个**具体的训练样本（Training Sample）**。以一个典型的**机器人控制任务**为例：**“用机械臂将蓝色方块堆叠在绿色方块上（Stack blue on green）”**。

这一个时间步（Timestep）的数据，进入模型时会被转化为以下这样一个长序列：

---

### 1. 概念层面的序列结构
在这个样本中，模型接收的序列大致是这样的顺序：
`[文本指令]` $\rightarrow$ `[图像 Patch]` $\rightarrow$ `[本体感觉状态]` $\rightarrow$ `[分隔符]` $\rightarrow$ `[动作]`

### 2. 具体的数据转化过程


#### A. 文本部分 (Text Instruction)
*   **原始输入**：`"Stack blue on green"`
*   **处理方式**：使用 SentencePiece 进行分词。
*   **数值范围**：$[0, 32000)$
*   **Gato 看到的 Token**：
    假设词表映射如下：`Stack`$\rightarrow 540$, `blue`$\rightarrow 120$, `on`$\rightarrow 30$, `green`$\rightarrow 980$。
    那么序列的开头就是：
    $$ [540, 120, 30, 980] $$

<alphaxiv-paper-citation title="Text Tokenization" page="3" first="Text is encoded" last="range [0, 32000)." />

#### B. 图像部分 (Image Observations)
*   **原始输入**：机械臂摄像头的画面（假设 $64 \times 64$ 像素）。
*   **处理方式**：
    1.  切分为 $16 \times 16$ 的小方块（Patches）。这意味着一张图有 $(64/16) \times (64/16) = 16$ 个 Patch。
    2.  按光栅顺序（从左到右，从上到下）排列。
    3.  每个 Patch 通过 ResNet 编码成一个向量，再映射到嵌入空间。
*   **Gato 看到的 Token**：
    虽然在内部它是向量，但在序列逻辑中，它占据了 16 个位置：
    $$ [\text{Patch}_1, \text{Patch}_2, \dots, \text{Patch}_{16}] $$

<alphaxiv-paper-citation title="Image Patching" page="3" first="Images are first" last="raster order," />

#### C. 本体感觉与状态 (Proprioception / Continuous Observations)
*   **原始输入**：机械臂当前的关节角度（例如：关节1是 $0.5$ 弧度，关节2是 $-1.2$ 弧度）。
*   **处理方式**：这是最关键的一步。
    1.  **$\mu$-law 压扩**：把连续浮点数映射到 $[-1, 1]$。
    2.  **离散化**：把 $[-1, 1]$ 切分成 1024 个桶（bins）。
    3.  **平移**：为了不和文本 ID 冲突，把这些 ID 加上 32000。
*   **数值范围**：$[32000, 33024)$
*   **Gato 看到的 Token**：
    假设 $0.5$ 对应桶 ID 500，$-1.2$ 对应桶 ID 100。
    那么序列接着是：
    $$ [32500, 32100, \dots] $$

<alphaxiv-paper-citation title="Continuous Values" page="3" first="Continuous values are" last="integer token indices." />

#### D. 分隔符 (Separator)
*   **作用**：告诉模型，“观测”结束了，下面该预测“动作”了。
*   **Gato 看到的 Token**：
    $$ [\text{SEPARATOR\_TOKEN}] $$

#### E. 动作部分 (Action - 训练目标)
*   **原始输入**：需要输出的关节力矩（Torques）或速度指令。
*   **处理方式**：同样使用 $\mu$-law 编码离散化。
*   **Gato 看到的 Token**：
    $$ [32800, 32650, 32900, \dots] $$

---

### 3. 完整的单一序列视图

把上面所有部分拼起来，Gato 在这一个时间步看到的**完整输入张量**就是这样一串整数：

$$ [ \underbrace{540, 120, 30, 980}_{\text{Text}}, \underbrace{\text{P}_1, \dots, \text{P}_{16}}_{\text{Image}}, \underbrace{32500, \dots}_{\text{State}}, \text{SEP}, \underbrace{\mathbf{32800}, \mathbf{32650}, \dots}_{\text{Action (Target)}} ] $$

注意，如果是**纯文本任务**（比如聊天），就没有中间的图像和状态 Token；如果是**玩 Atari 游戏**，可能就没有开头的文本指令，直接从图像 Patch 开始。

Gato 的强大之处就在于，它根本不在乎这些整数代表的是“单词 blue”还是“关节角度 0.5”，它只负责做一件事：**根据前面的所有整数，预测下一个整数是什么。**

<alphaxiv-paper-citation title="Sequence Ordering" page="3" first="Tokens form the" last="action tokens." />


## 和后面的 RT-2 比较


**Gato 不仅可以“看作”是 VLA（Vision-Language-Action）模型，它实际上是 VLA 概念的鼻祖和原型（Prototype）。**

虽然“VLA”这个术语在后来 Google 发布 **RT-2 (Robotic Transformer 2)** 时才真正变得炙手可热，但在 2022 年，Gato 就已经完整地定义了 VLA 的范式。

接下来对比下 **Gato 与现代 VLA（如 RT-2）的异同**，这对于理解具身智能的发展脉络至关重要。

---

### 1. 为什么说 Gato 是教科书级的 VLA？

VLA 的核心定义是：**将视觉（Vision）、语言（Language）和动作（Action）统一在一个 Transformer 模型中，实现端到端的推理。**

回顾我们在第二模块讲的内容，Gato 完美契合这三点：
*   **Vision**: 它处理图像 Patch（来自 Atari 或 机器人摄像头）。
*   **Language**: 它处理文本 Prompt（如“Stack blue block”）。
*   **Action**: 它输出离散化的动作 Token（关节力矩或按键）。

论文摘要的第一句就明确了这一点：“...works as a multi-modal, multi-task, multi-embodiment generalist policy.” 这本质上就是 VLA 的定义。 <alphaxiv-paper-citation title="Abstract" page="1" first="The agent, which" last="generalist policy." />

---

### 2. Gato (2022) vs. RT-2 (2023)：两条不同的技术路线

虽然都是 VLA，但 Gato 和后来的 RT-2 代表了两种截然不同的**构建哲学**。

#### A. 训练策略：“从头培养” vs. “半路出家”

*   **Gato (The Generalist Approach)**:
    Gato 的策略是 **"Train from Scratch"**（或者说是混合训练）。它把控制数据（Control Data）、视觉文本数据（Vision-Language Data）和纯文本数据（Text Data）**以 1:1:1 等比例混合**，同时喂给一个随机初始化的（或部分预训练的）网络。
    *   **优点**：模型从一开始就学习如何平衡不同模态，动作和语言在特征空间是平等的。
    *   **缺点**：需要极大的数据平衡技巧，且很难直接利用 LLM 涌现出的超强推理能力（因为模型只有 1.2B）。

*   **RT-2 (The VLM-Transfer Approach)**:
    RT-2 的策略是 **"Fine-tune a VLM"**。它先拿一个已经在大规模互联网数据上训练好的超大 VLM（如 PaLI-X 或 PaLM-E），然后把机器人的动作数据混进去进行微调（Co-fine-tuning）。
    *   **优点**：直接继承了 LLM 的世界知识和逻辑推理能力（比如识别“超人公仔”或“灭绝的动物”）。
    *   **缺点**：动作只是被当作一种特殊的“语言”强行塞进去的，推理速度通常很慢。

#### B. 动作的 Token 化：专用 vs. 通用

*   **Gato**:
    Gato 为动作设计了**专用的数值编码区间**（$[32000, \dots]$）。这意味着在 Gato 的词表中，“动作”和“单词”是物理隔离的。
    <alphaxiv-paper-citation title="Action Tokenization" page="3" first="Action tokens are" last="integer token indices." />

*   **RT-2**:
    RT-2 通常直接使用**文本 Token** 来表示动作。例如，如果机器人的动作是 `128`，它就输出文本 `"1"`, `"2"`, `"8"`。这使得它能直接利用预训练 LLM 的输出头，不需要修改模型结构。

#### C. 实时性（Real-time Inference）

这是 Gato 最令人敬佩的工程考量。
*   **Gato**: 只有 **1.18B 参数**。为什么？因为 DeepMind 必须保证它能以 **20Hz** 的频率控制真实的 Sawyer 机械臂。如果在做推理时延迟太高，机器人就会抖动甚至失控。
*   **现代 VLA**: 往往参数量巨大（7B, 13B, 甚至 50B+）。它们通常无法直接进行高频控制，需要配合一个小的“策略网络”或者运行在极低的频率下。

<alphaxiv-paper-citation title="Real-time Control" page="4" first="Gato uses a" last="latency requirements." />

---

### 3. 总结

Gato 是 VLA 的**先驱（Pioneer）**。

*   如果说 GPT-3 证明了“语言是通用的接口”；
*   那么 Gato 就证明了**“序列（Sequence）是通用的接口”**。

它告诉我们：只要你能把物理世界的信号（力、光、声）变成 Token，Transformer 就能学会控制物理世界。这正是今天具身智能（Embodied AI）最核心的信条。
