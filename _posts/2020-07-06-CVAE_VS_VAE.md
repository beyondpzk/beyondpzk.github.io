---
layout: post
title: CVAE_VS_VAE
date: 2020-07-06
categories: [Understandings]
toc:
    sidebar: left
    max_level: 4
---

[TOC]

# CVAE_VS_VAE

CVAE (Conditional Variational Autoencoder) 和 VAE (Variational Autoencoder) 的核心区别可以用两个字来概括：**“控制”**。

*   **VAE** 是**随机**生成的：你让它画一个人脸，它会随机画一个（可能是男是女，可能笑可能哭）。
*   **CVAE** 是**指定**生成的：你让它画一个人脸，并且**指定**“我要一个笑着的女性”，它就会按你的要求画。

下面从原理、结构、数学公式和直观理解四个维度详细对比：

---

### 1. 直观理解：盲盒 vs. 定制

| 特性 | VAE (无条件) | CVAE (有条件) |
| :--- | :--- | :--- |
| **比喻** | **抽盲盒**。你知道盒子里是手办，但你不知道会抽到哪一款。 | **3D打印定制**。你输入参数（比如：我要红色的、圆形的），机器就打印出符合参数的东西。 |
| **生成过程** | 随机采样 $z \sim N(0,1)$ $\to$ 生成图片。 | 随机采样 $z \sim N(0,1)$ **+ 条件 $c$** $\to$ 生成图片。 |
| **隐变量 $z$ 的含义** | $z$ 包含了**所有信息**（比如数字是几、写得歪不歪、粗细如何）。 | $z$ 只包含**剩余信息/风格信息**（比如写得歪不歪），而**核心内容**（数字是几）由条件 $c$ 决定。 |

---

### 2. 网络结构的区别 (怎么改代码)

CVAE 的改动非常简单，就是把条件 $c$（比如类别的 One-hot 向量）**拼接 (Concatenate)** 到输入里。

#### VAE 的结构
*   **Encoder**: 输入 $X$ $\to$ 输出 $\mu, \sigma$
*   **Latent**: $Z = \mu + \sigma \cdot \epsilon$
*   **Decoder**: 输入 $Z$ $\to$ 输出 $X_{recon}$

#### CVAE 的结构 (多了两步拼接)
*   **Encoder**: 输入 **$[X, c]$** (拼接) $\to$ 输出 $\mu, \sigma$
    *   *意思是：编码器不仅看图片，还要看标签，从而学习在给定标签下的分布。*
*   **Latent**: $Z = \mu + \sigma \cdot \epsilon$ (这一步没变)
*   **Decoder**: 输入 **$[Z, c]$** (拼接) $\to$ 输出 $X_{recon}$
    *   *意思是：解码器在生成时，不仅拿着隐变量 $z$，还拿着“说明书” $c$，告诉它要生成哪一类。*

---

### 3. 数学原理的区别 (概率视角)

VAE 试图最大化 $P(X)$ 的下界（ELBO），而 CVAE 试图最大化 $P(X|c)$ 的下界。

*   **VAE 的 Loss (ELBO)**:
    $$ \mathcal{L} = - \text{KL}(q(z|x) || p(z)) + \mathbb{E}_{q(z|x)}[\log p(x|z)] $$
    *   第一项：让后验分布接近标准正态分布。
    *   第二项：重构误差（给定 $z$ 还原 $x$）。

*   **CVAE 的 Loss (Conditional ELBO)**:
    $$ \mathcal{L} = - \text{KL}(q(z|x, \mathbf{c}) || p(z|\mathbf{c})) + \mathbb{E}_{q(z|x, \mathbf{c})}[\log p(x|z, \mathbf{c})] $$
    *   **区别**：所有的概率分布里都多了一个条件 $\mathbf{c}$。
    *   通常假设先验 $p(z|c)$ 依然是 $N(0, I)$（即隐变量 $z$ 和条件 $c$ 独立），所以 KL 散度那一项计算方式基本不变。

---

### 4. 为什么 CVAE 更好用？(应用场景)

假设我们在训练 MNIST 手写数字数据集：

*   **如果你用 VAE**：
    *   训练完后，你想生成一个数字 "8"。
    *   你做不到。你只能随机采样 $z$，运气好是 8，运气不好是 3。
    *   你会发现 $z$ 的空间里，数字是混在一起的（虽然有聚类，但边界模糊）。

*   **如果你用 CVAE**：
    *   训练时，你告诉模型：这是图片，这是标签 "8"。
    *   **推理时**：
        1.  准备一个随机噪声 $z$（决定字迹潦草程度）。
        2.  准备一个 One-hot 向量 $c=[0,0,0,0,0,0,0,0,1,0]$（代表 8）。
        3.  把 $z$ 和 $c$ 拼起来喂给 Decoder。
        4.  **必出 "8"**。
    *   **玩法升级**：你可以固定 $z$ 不变，只改变 $c$ 从 0 到 9。你会看到**同样笔迹/风格**的 0 到 9。这就是 CVAE 强大的**解耦能力**（内容由 $c$ 控制，风格由 $z$ 控制）。

### 总结

| | VAE | CVAE |
| :--- | :--- | :--- |
| **输入** | 图片 $X$ | 图片 $X$ + 标签 $C$ |
| **生成控制** | **不可控** (随机) | **可控** (指定类别/特征) |
| **隐空间 $Z$** | 混合了内容和风格 | 纯粹的风格/变体 (内容被剥离到 $C$ 中) |
| **适用场景** | 降维、去噪、无条件生成 | 图像修复(Inpainting)、文本转图像、风格迁移 |

**一句话总结：CVAE 就是给 VAE 的 Encoder 和 Decoder 都发了一份“说明书”（条件 Condition），让它不再瞎猜，而是按需生成。**




