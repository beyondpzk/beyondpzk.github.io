---
layout: post
title: DETR3D
date: 2021-10-13
categories: [Peception]
tags: Peception
---
<!--more-->


- [paper地址](https://arxiv.org/abs/2110.06922)

# DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries

## sketch the main points

从题目中可以看出来, 核心就是 3D-to-2D 的queries. 
整体的做法是

1. 使用resnet+fpn 提取multi-level的image features

2. 并没有像bevformer或者lss那样构建bev空间的过程, 这里是用一组sparse queries来实现的. 类似于DETR中的object query, 这里是3D obejct queries.
具体做法是Head decoder的每一层的本质是为了更新 3D-object-query, 
即paper里面的公式(1)->(4). 

输入object query, 产生reference points, 这里可以把reference points 想象成为 bbox的中心. 然后把reference points 投影到每个相机上, 
根据相机上的位置,进行双线性插值,拿到这个query 对应的feature, 最后多个相机的feature进行取平均(有效的数量), 得到新的feature f, 
那么这层输出的query 就等于 (query + f). 

3. 最后就是用更新后的query 接bbox-branch 和 cls-branch 做预测; 这里也用了DETR中的set-to-set 的二分匹配方式来做label-assign.

## 思考

1. 这里的query 代表着什么?

其实这里通过3D-to-2D的操作,已经把query 具象化了, 可以认为和DETR中相同的含义,即3D object query, 通过模型生产出3d的点,或者是bbox的中心. 

