---
layout: post
title: DE_VS_SDE
date: 2023-09-18
categories: [Understandings]
toc:
    sidebar: left
    max_level: 4
---

[TOC]

# 微分方程(DE)对比随机微分方程(SDE)

为了方便,我们可以用一个变量,即ODE,而不是PDE来解说.

简单来说：
*   **ODE (Ordinary Differential Equation)** 是**确定性**的。只要给定初始状态，未来的每一步都是注定的。
*   **SDE (Stochastic Differential Equation)** 是**随机性**的。它在确定性的规律上叠加了“噪声”或“波动”。给定初始状态，未来有无数种可能性，我们只能预测其概率分布。

---

### 1. 核心区别与联系

#### 区别 (Difference)

| 特性 | DE (常微分方程) | SDE (随机微分方程) |
| :--- | :--- | :--- |
| **本质** | **确定性 (Deterministic)** | **随机性 (Stochastic/Probabilistic)** |
| **驱动力** | 只有平滑的物理规律 (如速度、衰减) | 物理规律 + **随机噪声 (白噪声)** |
| **解的形式** | 一条确定的轨迹 (函数 $x(t)$) | 一个随机过程 (Stochastic Process $X_t$) |
| **重复实验** | 每次运行结果完全一样 | 每次运行结果都不一样 (路径不同) |
| **微积分法则** | 牛顿-莱布尼茨微积分 (标准链式法则) | **伊藤微积分 (Itô Calculus)** (需要修正项) |
| **典型应用** | 行星轨道、单摆、化学反应速率 | 股票价格、布朗运动、种群受环境扰动 |

#### 联系 (Connection)

1.  **退化关系**：如果 SDE 中的噪声项系数（扩散项）变为 0，SDE 就退化成了 ODE。
2.  **均值关系**：在很多情况下，SDE 的无数条随机路径的**平均值（期望）**，往往遵循某种 ODE 的规律。
3.  **物理背景**：SDE 通常是对 ODE 模型的修正。我们在理想环境下建立 ODE 模型，考虑到现实世界的干扰（温度波动、市场情绪），加上噪声项就变成了 SDE。

---

### 2. 数学形式对比

假设我们要描述一个变量 $X$ 随时间 $t$ 的变化。

#### DE (ODE) 模型
$$ \frac{dX}{dt} = \mu(X, t) $$
或者写成微分形式：
$$ dX = \mu(X, t) dt $$
*   $\mu(X, t)$：**漂移项 (Drift)**，代表系统的确定性趋势（如增长率）。

#### SDE 模型
$$ dX_t = \underbrace{\mu(X_t, t) dt}_{\text{确定性部分}} + \underbrace{\sigma(X_t, t) dW_t}_{\text{随机噪声部分}} $$
*   $\mu$：漂移项 (Drift)，同 ODE。
*   $\sigma$：**扩散项 (Diffusion)**，代表噪声的强度（波动率）。
*   $dW_t$：**维纳过程 (Wiener Process)** 或布朗运动的增量。
    *   $dW_t \sim N(0, dt)$，即它服从均值为0，方差为 $dt$ 的正态分布。  (记住这个,后面可以用来证明 $(dW)^2=dt$)

---

### 3. 具体例子：指数增长模型

让我们用最经典的**马尔萨斯人口模型**（在金融中对应**几何布朗运动 GBM**）来对比。

**场景**：假设有一个细菌群落（或一只股票），其固有增长率为 $\mu$。

1.  **ODE 视角 (理想环境)**：
    细菌按固定比率增长。
    $$ dX = \mu X dt $$
    *解*：$X(t) = X_0 e^{\mu t}$ (平滑的指数曲线)。

2.  **SDE 视角 (真实环境)**：
    细菌增长受环境温度随机波动影响。
    $$ dX_t = \mu X_t dt + \sigma X_t dW_t $$
    *解*：没有解析函数的“公式”，只有统计性质。路径是锯齿状的。

---

### 4. Python 代码与可视化

我们将使用 Python 的 `numpy` 和 `matplotlib` 来模拟这两个方程。
*   **ODE** 使用欧拉法（或直接解析解）。
*   **SDE** 使用 **Euler-Maruyama 方法**（这是求解 SDE 最基础的数值方法）。

```python
import numpy as np
import matplotlib.pyplot as plt

# 设置随机种子以便复现
np.random.seed(42)

# === 参数设置 ===
T = 2.0        # 总时间
N = 1000       # 时间步数
dt = T / N     # 每一步的时间间隔
t = np.linspace(0, T, N+1) # 时间轴

mu = 0.5       # 漂移系数 (Drift): 确定性增长率
sigma = 0.3    # 扩散系数 (Diffusion): 波动率/噪声强度
X0 = 100       # 初始值

# === 1. ODE (常微分方程) 求解 ===
# 模型: dX = mu * X * dt
# 解析解: X(t) = X0 * exp(mu * t)
X_ode = X0 * np.exp(mu * t)

# === 2. SDE (随机微分方程) 求解 ===
# 模型: dX = mu * X * dt + sigma * X * dW
# 方法: Euler-Maruyama 数值模拟
# 我们模拟多条路径来看看随机性的分布

num_paths = 10 # 模拟 10 条不同的平行宇宙
X_sde = np.zeros((N+1, num_paths))
X_sde[0, :] = X0

for i in range(N):
    # 生成布朗运动增量 dW
    # dW 服从 N(0, dt)，即 sqrt(dt) * 标准正态分布
    dW = np.sqrt(dt) * np.random.randn(num_paths)
    
    # 当前的值
    X_current = X_sde[i, :]
    
    # Euler-Maruyama 公式:
    # X_{t+1} = X_t + mu*X_t*dt + sigma*X_t*dW
    X_next = X_current + mu * X_current * dt + sigma * X_current * dW
    
    X_sde[i+1, :] = X_next

# === 3. 可视化绘图 ===
plt.figure(figsize=(12, 6))

# 画 SDE 的多条随机路径
for i in range(num_paths):
    plt.plot(t, X_sde[:, i], lw=1, alpha=0.6, label='SDE Path' if i==0 else None)

# 画 ODE 的确定性路径
plt.plot(t, X_ode, 'k-', lw=3, label='ODE (Deterministic)')

# 画 SDE 路径的平均值 (理论上应该接近 ODE，但受伊藤引理影响会有偏移)
plt.plot(t, np.mean(X_sde, axis=1), 'r--', lw=2, label='Mean of SDE Paths')

plt.title(f'DE vs SDE Comparison\nDrift($\mu$)={mu}, Diffusion($\sigma$)={sigma}', fontsize=14)
plt.xlabel('Time (t)', fontsize=12)
plt.ylabel('Value X(t)', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)

plt.show()
```

### 代码结果解析

当运行这段代码时，会看到一张图：

1.  **黑色粗线 (ODE)**：这是一条非常平滑、完美的指数增长曲线。它代表了“理想状态”下的发展。
2.  **彩色细线 (SDE)**：这些线条虽然整体趋势是向上的（受 $\mu$ 驱动），但它们充满了锯齿状的波动。
    *   有的路径可能运气好，涨得比 ODE 还快。
    *   有的路径可能运气差，甚至跌破初始值。
    *   这就是**随机性**。
3.  **红色虚线 (SDE 均值)**：如果你模拟足够多的路径（比如 10000 条），取平均值，你会发现它是一条平滑曲线。

### 深入一点：伊藤引理 (Itô's Lemma) 的影响

我们会发现，SDE 的平均值（红色虚线）并不完全重合于 ODE（黑色实线），或者说 SDE 的中位数往往低于 ODE。

这是 SDE 和 DE 最深刻的区别之一：**微积分规则变了**。

*   在普通微积分中，$dx \cdot dx \approx 0$。
*   在随机微积分（伊藤积分）中，$(dW_t)^2 = dt$。这意味着二阶项不能忽略！

对于几何布朗运动（上面的例子），SDE 的解析解其实是：
$$ X_t = X_0 \exp\left( (\mu - \frac{1}{2}\sigma^2)t + \sigma W_t \right) $$
注意那个 $-\frac{1}{2}\sigma^2$。这是**伊藤修正项**。因为噪声的存在，长期的增长率实际上被波动率“拖累”了。这就是为什么在股市中，高波动率往往意味着长期持有价值的损耗（Volatility Drag）。

### 小结

*   **DE** 是描绘**骨架**：它告诉我们系统在没有干扰时的主要机制。
*   **SDE** 是描绘**血肉**：它在骨架上增加了现实世界的不可预测性。
*   **联系**：SDE 是 ODE 的推广。当我们要建模真实世界（金融市场、布朗粒子、信号处理）时，必须从 ODE 跨越到 SDE。


## 最明显的区别


### 1. ODE 和 SDE 最明显的区别是什么？

如果只用一句话概括，最明显的区别在于**“光滑度”与“可微性”**。

*   **ODE 的轨迹是光滑的**：如果你放大 ODE 的解曲线，它看起来是一条直线。它在任何一点都有确定的切线（速度）。
*   **SDE 的轨迹是粗糙的（分形的）**：无论你把 SDE 的轨迹放大多少倍，它依然是锯齿状的，永远看不到平滑的直线。
    *   **数学结论**：布朗运动路径处处连续，但**处处不可导**。你无法画出它在某一点的切线，因为它的方向在无限快地变化。

**直观对比：**
*   **ODE** 像是一个人在平地上跑步，轨迹是一条平滑的弧线。
*   **SDE** 像是一个花粉粒子在水中被无数水分子撞击（布朗运动），它在宏观上移动，但微观上在疯狂抖动。

---

### 2. “二阶项公式” $(dW)^2=dt$是什么含义？


#### (1) 核心来源：$dW_t \approx \sqrt{dt}$

在普通微积分（ODE）中，时间增量 $dt$ 非常小。
在随机微积分（SDE）中，噪声增量 $dW_t$ 的量级是 $\sqrt{dt}$。

*   举例：如果 $dt = 0.01$，那么 $dt^2 = 0.0001$（太小了，忽略）。
*   但是：$\sqrt{dt} = 0.1$。
*   所以：$(dW_t)^2 \approx (\sqrt{dt})^2 = dt$。**这不能忽略！**

#### (2) 泰勒展开的差异

假设我们要对一个函数 $f(x)$ 求变化量 $df$。

**普通微积分 (ODE):**
根据泰勒展开：
$$ df = f'(x)dx + \frac{1}{2}f''(x)(dx)^2 + \dots $$
因为 $dx \approx dt$，所以 $(dx)^2 \approx dt^2 \approx 0$。二阶项被扔掉了。
$$ \text{结果：} \quad df = f'(x)dx $$

**随机微积分 (SDE):**
这里 $dx$ 包含了噪声项 $\sigma dW$。
$$ (dx)^2 \approx (\sigma dW)^2 = \sigma^2 (dW)^2 = \sigma^2 dt $$
**注意！** 二阶项 $(dx)^2$ 并没有变成 0，而是变成了一个与 $dt$ 同量级的东西。
$$ \text{结果 (伊藤公式)：} \quad df = f'(x)dx + \underbrace{\frac{1}{2}f''(x)\sigma^2 dt}_{\text{二阶修正项}} $$

#### (3) 那个 $-\frac{1}{2}\sigma^2$ 是什么意思？（波动率拖累）

在金融和许多物理模型中，这个二阶项通常表现为 $-\frac{1}{2}\sigma^2$。它的现实含义是：**波动本身会吞噬增长**。

**通俗例子（波动率拖累）：**
假设你有 100 元。
*   **情况 A (ODE, 无波动)**：每年稳赚 10%。两年后：$100 \times 1.1 \times 1.1 = 121$。
*   **情况 B (SDE, 有波动)**：第一年赚 50%，第二年亏 50%（算术平均收益率是 0%）。
    *   结果：$100 \times 1.5 \times 0.5 = 75$。
    *   **亏了！** 虽然平均涨幅是 0，但你亏了 25 元。

这就是二阶项的含义：**仅仅是因为存在波动（$\sigma$），长期的复利增长率就会低于算术平均增长率。**

公式体现为：
$$ \text{实际增长率} = \mu (\text{名义漂移}) - \frac{1}{2}\sigma^2 (\text{波动修正}) $$

---

### 3. Python 可视化：验证二阶项的存在

我们通过代码来验证这一点。我们将模拟一个 SDE，看看它的**中位数路径**是否真的比 ODE 的路径低，且正好低了 $\frac{1}{2}\sigma^2$。

```python
import numpy as np
import matplotlib.pyplot as plt

# === 参数 ===
T = 1.0
N = 1000
dt = T/N
t = np.linspace(0, T, N+1)

mu = 0.5        # 名义增长率
sigma = 0.6     # 波动率 (设置大一点，让二阶项效果更明显)
X0 = 100
num_paths = 2000 # 模拟大量路径以取平均

# === 1. ODE 路径 (普通微积分) ===
# 假设没有波动，或者忽略二阶项
# X_t = X0 * e^(mu * t)
path_ode = X0 * np.exp(mu * t)

# === 2. SDE 模拟 (几何布朗运动) ===
# dX = mu*X*dt + sigma*X*dW
# 理论解 (伊藤积分): X_t = X0 * exp( (mu - 0.5*sigma^2)t + sigma*W_t )

# 生成布朗运动
dW = np.sqrt(dt) * np.random.randn(num_paths, N)
W = np.cumsum(dW, axis=1)
W = np.hstack([np.zeros((num_paths, 1)), W]) # 在 t=0 处补0

# 计算 SDE 的精确解路径
# 注意这里的指数部分： (mu - 0.5 * sigma^2)
path_sde_all = X0 * np.exp((mu - 0.5 * sigma**2) * t + sigma * W)

# 计算所有路径的几何平均 (Geometric Mean) 或中位数
# 这代表了去除随机噪声后，系统的“真实趋势”
path_sde_median = np.median(path_sde_all, axis=0)

# === 3. 绘图对比 ===
plt.figure(figsize=(10, 6))

# 画 50 条 SDE 随机路径作为背景
plt.plot(t, path_sde_all[:50].T, color='gray', alpha=0.1)

# 画 ODE 路径 (如果不考虑二阶项)
plt.plot(t, path_ode, 'b-', linewidth=3, label=r'ODE: $e^{\mu t}$ (Wrong for SDE center)')

# 画 SDE 的统计中位线
plt.plot(t, path_sde_median, 'r--', linewidth=3, label=r'SDE Median: $e^{(\mu - 0.5\sigma^2)t}$')

plt.title(f'Visualizing the Itô Correction Term (-0.5 $\sigma^2$)\nVolatility $\sigma$={sigma}', fontsize=14)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.xlabel('Time')
plt.ylabel('Value')

plt.show()
```

### 代码结果解读

运行这段代码后，你会看到：

1.  **蓝线 (ODE)**：高高在上。这是如果我们忽略二阶项，天真地认为平均收益就是 $\mu$ 时预期的曲线。
2.  **红虚线 (SDE 中位数)**：明显低于蓝线。
3.  **差距**：蓝线和红线之间的差距，就是由 **$-\frac{1}{2}\sigma^2$** 造成的。

**结论**：
SDE 中的二阶项不是数学游戏，它是对现实世界**“波动有代价”**这一物理事实的数学描述。如果不加这一项，模型预测就会偏高（在金融里意味着你会高估收益，在物理里意味着能量守恒计算错误）。


## 证明 $(dW)^2=dt$


1.  $t$ 是时间**。$dt$ 代表极短的一段时间间隔。
2.  **$(dW)^2 = dt$ 不是代数上的相等，而是概率极限上的相等**。

要理解为什么“随机增量的平方等于时间”，我们需要从**布朗运动的微观起源（随机游走）**来看。

---

### 1. 直观解释：抛硬币与步长

想象我们在做一个**随机游走（Random Walk）**的游戏，这其实就是布朗运动的离散版本。

*   **规则**：每过一小段时间 $\Delta t$，我们抛一枚硬币。
    *   正面：向前走一步，距离为 $\Delta x$。
    *   反面：向后走一步，距离为 $-\Delta x$。

这里的 $\Delta x$ 就是 $dW$（位置的变化量）。

#### 关键问题：步长 $\Delta x$ 应该设为多大？

如果我们想让这个运动在时间趋于 0 时变成标准的布朗运动，物理学告诉我们 $x=\frac{1}{2}at^2$：
**距离的量级必须是时间的平方根。**

$$ \Delta x = \pm \sqrt{\Delta t} $$  

为什么要这样设？
*   如果 $\Delta x = \Delta t$（像普通速度一样）：随着时间切分得越细，粒子根本动不起来，速度太慢。
*   只有当 $\Delta x \approx \sqrt{\Delta t}$ 时，粒子才能表现出那种剧烈的、锯齿状的布朗运动特征。

#### 现在，我们来算平方

既然每一步的移动距离是 $\Delta x = \pm \sqrt{\Delta t}$，那么无论你是向前走还是向后走，**移动距离的平方**是确定的：

$$ (\Delta x)^2 = (\pm \sqrt{\Delta t})^2 = \Delta t $$

换成微分符号，就是：
$$ (dW)^2 = dt $$

**结论**：
虽然 $dW$ 本身是随机的（可能是正，可能是负），但它的**平方**却是一个确定的值（时间间隔本身）。因为正负号被平方消掉了，而步长的大小被严格锁定为 $\sqrt{dt}$。

---

### 2. 统计解释：方差的累积

如果从统计学角度看，$dW$ 是一个随机变量，服从正态分布：
$$ dW \sim N(0, dt) $$
意思是：均值为 0，**方差为 $dt$**。

根据方差的定义：$Var(X) = E[X^2] - (E[X])^2$。
对于 $dW$：
$$ dt = E[(dW)^2] - 0^2 $$
$$ \Rightarrow E[(dW)^2] = dt $$

也就是说，$(dW)^2$ 的**期望值**是 $dt$。

在随机微积分中，有一个强大的定律（大数定律的一种形式）告诉我们：当我们把时间切得无限细时，**随机变量的平方和会收敛于它的期望值和**。

所以，虽然对单个点来说有波动，但在积分意义下，我们就可以直接把 $(dW)^2$ 替换成 $dt$。

---

### 3. 为什么普通微积分里 $(dx)^2 = 0$？

这是为了对比理解：

*   **普通运动 (ODE)**：
    速度 $v$ 是有限的。
    位移 $dx = v \cdot dt$。
    平方：$(dx)^2 = v^2 \cdot (dt)^2$。
    因为 $dt$ 很小（比如 0.001），$(dt)^2$ 就更小（0.000001），可以忽略不计，视为 0。

*   **布朗运动 (SDE)**：
    速度是无穷大的（剧烈抖动）。
    位移 $dW \approx \sqrt{dt}$。
    平方：$(dW)^2 \approx (\sqrt{dt})^2 = dt$。
    $dt$ 是**一阶无穷小**，不能忽略！

---

### 4. Python 代码验证：二次变差 (Quadratic Variation)

我们可以写一段代码来验证这个反直觉的公式。
我们将时间 $T=1$ 切分成 $N$ 份，计算所有 $dW$ 的平方和。
*   如果 $(dW)^2 = 0$，和应该接近 0。
*   如果 $(dW)^2 = dt$，和应该接近 $\sum dt = T = 1$。

```python
import numpy as np
import matplotlib.pyplot as plt

def check_quadratic_variation(N):
    T = 1.0
    dt = T / N
    
    # 生成 N 个随机增量 dW
    # dW ~ N(0, dt) -> sqrt(dt) * N(0, 1)
    dW = np.sqrt(dt) * np.random.randn(N)
    
    # 计算 dW 的平方
    dW_squared = dW ** 2
    
    # 求和
    sum_squared = np.sum(dW_squared)
    
    return sum_squared

# === 实验：随着切分份数 N 的增加，(dW)^2 的总和会发生什么？ ===
N_values = [10, 100, 1000, 10000, 100000, 1000000]
results = []

print(f"{'N (Steps)':<10} | {'Sum of (dW)^2':<15} | {'Error from T=1.0':<15}")
print("-" * 45)

for N in N_values:
    res = check_quadratic_variation(N)
    results.append(res)
    print(f"{N:<10} | {res:.5f}         | {abs(res - 1.0):.5f}")

# === 可视化 ===
plt.figure(figsize=(8, 5))
plt.plot(N_values, results, 'o-', label=r'$\sum (dW)^2$')
plt.axhline(y=1.0, color='r', linestyle='--', label='Theoretical T=1.0')
plt.xscale('log')
plt.xlabel('Number of Time Steps (N)')
plt.ylabel('Sum of Squared Increments')
plt.title('Verification of $(dW)^2 = dt$\n(Quadratic Variation converges to T)')
plt.legend()
plt.grid(True)
plt.show()
```

### 代码结果解读

当运行这段代码，你会发现：
1.  当 $N=10$ 时，结果可能是 0.8 或 1.2，波动很大。
2.  当 $N=1,000,000$ 时，结果会非常精确地接近 **1.0**。

这意味着 $\sum (dW)^2 = \sum dt = T$。
去掉求和符号，这就验证了在微观层面：**$(dW)^2$ 的行为表现得就和 $dt$ 一模一样。**
